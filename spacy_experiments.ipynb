{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries and Packages\n",
    "import sys  \n",
    "import csv\n",
    "import spacy\n",
    "from time import process_time\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Set global variables\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500  movies processed\n",
      "1000  movies processed\n",
      "1500  movies processed\n",
      "2000  movies processed\n",
      "2500  movies processed\n",
      "3000  movies processed\n",
      "3500  movies processed\n",
      "4000  movies processed\n",
      "4500  movies processed\n",
      "5000  movies processed\n",
      "5500  movies processed\n",
      "6000  movies processed\n",
      "6500  movies processed\n",
      "7000  movies processed\n",
      "7500  movies processed\n",
      "8000  movies processed\n",
      "8500  movies processed\n",
      "9000  movies processed\n",
      "9500  movies processed\n",
      "10000  movies processed\n",
      "10500  movies processed\n",
      "11000  movies processed\n",
      "11500  movies processed\n",
      "12000  movies processed\n",
      "12500  movies processed\n",
      "13000  movies processed\n",
      "13500  movies processed\n",
      "14000  movies processed\n",
      "14500  movies processed\n",
      "15000  movies processed\n",
      "15500  movies processed\n",
      "16000  movies processed\n",
      "16500  movies processed\n",
      "17000  movies processed\n",
      "17500  movies processed\n",
      "18000  movies processed\n",
      "18500  movies processed\n",
      "19000  movies processed\n",
      "19500  movies processed\n",
      "20000  movies processed\n",
      "20500  movies processed\n",
      "21000  movies processed\n",
      "21500  movies processed\n",
      "22000  movies processed\n",
      "22500  movies processed\n",
      "23000  movies processed\n",
      "23500  movies processed\n",
      "24000  movies processed\n",
      "24500  movies processed\n",
      "25000  movies processed\n",
      "25500  movies processed\n",
      "26000  movies processed\n",
      "26500  movies processed\n",
      "27000  movies processed\n",
      "27500  movies processed\n",
      "28000  movies processed\n",
      "28500  movies processed\n",
      "29000  movies processed\n",
      "29500  movies processed\n",
      "30000  movies processed\n",
      "30500  movies processed\n",
      "31000  movies processed\n",
      "31500  movies processed\n",
      "32000  movies processed\n",
      "32500  movies processed\n",
      "33000  movies processed\n",
      "33500  movies processed\n",
      "34000  movies processed\n",
      "34500  movies processed\n",
      "Processing Done\n",
      "Time to process  34886  records:  2524.3125\n",
      "Average processing timer per record:  0.0723588975520266\n",
      "('Should a Woman Divorce?', Grace Roberts (played by Lea Leland), marries rancher Edward Smith, who is revealed to be a neglectful, vice-ridden spouse. They have a daughter, Vivian. Dr. Franklin (Leonid Samoloff) whisks Grace away from this unhappy life, and they move to New York under aliases, pretending to be married (since surely Smith would not agree to a divorce). Grace and Franklin have a son, Walter (Milton S. Gould). Vivian gets sick, however, and Grace and Franklin return to save her. Somehow this reunion, as Smith had assumed Grace to be dead, causes the death of Franklin. This plot device frees Grace to return to her father's farm with both children.[1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if debug:\n",
    "    start_time = process_time()\n",
    "\n",
    "# Set the appropriate input file\n",
    "# movie_plots_import_file = \"wiki_movie_plots_sample.csv\" # 3248 Movies\n",
    "movie_plots_import_file = \"wiki_movie_plots_deduped.csv\" #34,892 Movies\n",
    "\n",
    "\n",
    "# Setup the plots array\n",
    "plots = []\n",
    "\n",
    "# Open import file and export all plots and titles into plots[]\n",
    "with open(movie_plots_import_file, 'r', encoding='utf-8') as movie_plot_csv_file:\n",
    "    reader = csv.reader(movie_plot_csv_file)\n",
    "    next(reader, None)  # Skip the csv header row\n",
    "    count=0\n",
    "\n",
    "    for row in reader:\n",
    "        plots.append((row[1],nlp(row[7])))\n",
    "        count = count + 1\n",
    "        if(count % 500 == 0):\n",
    "            print(count, \" movies processed\")\n",
    "            \n",
    "print(\"Processing Done\")\n",
    "\n",
    "if debug:\n",
    "    end_time = process_time()\n",
    "    print(\"Time to process \", count, \" records: \", end_time - start_time)\n",
    "    print(\"Average processing timer per record: \", (end_time- start_time)/count)\n",
    "\n",
    "# Print example when finished\n",
    "print(plots[100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define generic similarity function\n",
    "def simularity_printer(firstId, secondId):\n",
    "    if debug:\n",
    "        start_time = process_time()\n",
    "    print(\"Similarity of \", plots[firstId][0], \" and \", plots[secondId][0], \":\", plots[firstId][1].similarity(plots[secondId][1]))\n",
    "    if debug:\n",
    "        end_time = process_time()\n",
    "        print(\"Simularity calculation runtime \", end_time - start_time)\n",
    "\n",
    "# Define generic 'best match' function\n",
    "def best_match(id):\n",
    "    if debug:\n",
    "        start_time = process_time()\n",
    "    best_score = 0\n",
    "    best_match = \"None\"\n",
    "    for plot in plots:\n",
    "        if plot == plots[id]:\n",
    "            continue\n",
    "        score = plots[id][1].similarity(plot[1])\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = plot[0]\n",
    "    print(\"Best match for \",plots[id][0],\" was: \",best_match,\" with score of \", best_score)\n",
    "    if debug:\n",
    "        end_time = process_time()\n",
    "        print(\"Time to find best match from \", len(plots), \" films: \", end_time - start_time)\n",
    "        print(\"Average search time per film: \", (end_time-start_time)/len(plots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some tests/examples\n",
    "simularity_printer(10, 250)\n",
    "simularity_printer(10, 300)\n",
    "simularity_printer(27, 72)\n",
    "simularity_printer(27, 207)\n",
    "simularity_printer(27, 270)\n",
    "\n",
    "best_match(2000)\n",
    "best_match(2500)\n",
    "best_match(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_match(2915)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best matches for In This Our Life are:\n",
      "1. Diary of a Mad Black Woman \t 0.9897135738481504\n",
      "2. Night World \t 0.9886595584147576\n",
      "3. The Young Philadelphians \t 0.9881839554328727\n",
      "4. Peyton Place \t 0.9879365048790834\n",
      "5. Phone Call from a Stranger \t 0.9878915190776927\n",
      "6. Ten North Frederick \t 0.9875224143707632\n",
      "7. Devotion \t 0.9872187233170223\n",
      "8. St. Elmo's Fire \t 0.9871605721632734\n",
      "9. Red-Headed Woman \t 0.9871487847600823\n",
      "10. Chained \t 0.9871139572867368\n",
      "\n",
      "Time to find best match from  34886  films:  50.546875\n",
      "Average search time per film:  0.0014489157541707274\n"
     ]
    }
   ],
   "source": [
    "def top10_match(id):\n",
    "    if debug:\n",
    "        start_time = process_time()\n",
    "    matches = [['BASE VALUE', 0]] # Schema: [ [title, score], [title, score]... ]\n",
    "    \n",
    "    for plot in plots:\n",
    "        if plot == plots[id]:\n",
    "            continue\n",
    "\n",
    "        score = plots[id][1].similarity(plot[1]) # Get Similarity between current movie and match movie\n",
    "\n",
    "        matches.append([plot[0], score]) # Add movie title and score to end of list\n",
    "        matches = sorted(matches, key=lambda x: x[1], reverse=True) # Sort list by scores\n",
    "        if len(matches) > 10: # Remove lowest score if length > 10\n",
    "            matches.pop()\n",
    "    \n",
    "    end_time = process_time()\n",
    "    # Print Results\n",
    "    print(\"The best matches for\", plots[id][0], \"are:\")\n",
    "    i = 1\n",
    "    for match in matches:\n",
    "        print(str(i) + \".\", match[0], \"\\t\", match[1])\n",
    "        i+=1\n",
    "\n",
    "    print(\"\\nTime to find best match from \", len(plots), \" films: \", end_time - start_time)\n",
    "    print(\"Average search time per film: \", (end_time-start_time)/len(plots))\n",
    "\n",
    "top10_match(3331)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed  1000  movies\n",
      "Processed  2000  movies\n",
      "Processed  3000  movies\n",
      "Processed  4000  movies\n",
      "Processed  5000  movies\n",
      "Processed  6000  movies\n",
      "Processed  7000  movies\n",
      "Processed  8000  movies\n",
      "Processed  9000  movies\n",
      "Processed  10000  movies\n",
      "Processed  11000  movies\n",
      "Processed  12000  movies\n",
      "Processed  13000  movies\n",
      "Processed  14000  movies\n",
      "Processed  15000  movies\n",
      "Processed  16000  movies\n",
      "Processed  17000  movies\n",
      "Processed  18000  movies\n",
      "Processed  19000  movies\n",
      "Processed  20000  movies\n",
      "Processed  21000  movies\n",
      "Processed  22000  movies\n",
      "Processed  23000  movies\n",
      "Processed  24000  movies\n",
      "Processed  25000  movies\n",
      "Processed  26000  movies\n",
      "Processed  27000  movies\n",
      "Processed  28000  movies\n",
      "Processed  29000  movies\n",
      "Processed  30000  movies\n",
      "Processed  31000  movies\n",
      "Processed  32000  movies\n",
      "Processed  33000  movies\n",
      "Processed  34000  movies\n",
      "Processed all  34886  movies\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "import io\n",
    "\n",
    "best_matches=list()\n",
    "\n",
    "count = 0\n",
    "\n",
    "for plot in plots:\n",
    "    matches = [['BASE VALUE', 0]] # Schema: [ [title, score], [title, score]... ]\n",
    "    \n",
    "    for compplot in plots:\n",
    "        if compplot == plot:\n",
    "            continue\n",
    "\n",
    "        score = plot[1].similarity(compplot[1]) # Get Similarity between current movie and match movie\n",
    "\n",
    "        matches.append([compplot[0], score]) # Add movie title and score to end of list\n",
    "        matches = sorted(matches, key=lambda x: x[1], reverse=True) # Sort list by scores\n",
    "        if len(matches) > 10: # Remove lowest score if length > 10\n",
    "            matches.pop()\n",
    "    \n",
    "    best_matches.append((plot[0],matches))\n",
    "    count = count + 1\n",
    "    if(count % 1000 == 0):\n",
    "        print(\"Processed \", count, \" movies\")\n",
    "print (\"Processed all \", count, \" movies\")\n",
    "\n",
    "f = open('toptennostopwords.dat','wb')\n",
    "pickle.dump(best_matches,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 movie plots cleaned\n",
      "200 movie plots cleaned\n",
      "300 movie plots cleaned\n",
      "400 movie plots cleaned\n",
      "500 movie plots cleaned\n",
      "600 movie plots cleaned\n",
      "700 movie plots cleaned\n",
      "800 movie plots cleaned\n",
      "900 movie plots cleaned\n",
      "1000 movie plots cleaned\n",
      "1100 movie plots cleaned\n",
      "1200 movie plots cleaned\n",
      "1300 movie plots cleaned\n",
      "1400 movie plots cleaned\n",
      "1500 movie plots cleaned\n",
      "1600 movie plots cleaned\n",
      "1700 movie plots cleaned\n",
      "1800 movie plots cleaned\n",
      "1900 movie plots cleaned\n",
      "2000 movie plots cleaned\n",
      "2100 movie plots cleaned\n",
      "2200 movie plots cleaned\n",
      "2300 movie plots cleaned\n",
      "2400 movie plots cleaned\n",
      "2500 movie plots cleaned\n",
      "2600 movie plots cleaned\n",
      "2700 movie plots cleaned\n",
      "2800 movie plots cleaned\n",
      "2900 movie plots cleaned\n",
      "3000 movie plots cleaned\n",
      "3100 movie plots cleaned\n",
      "3200 movie plots cleaned\n",
      "3300 movie plots cleaned\n",
      "3400 movie plots cleaned\n",
      "3500 movie plots cleaned\n",
      "3600 movie plots cleaned\n",
      "3700 movie plots cleaned\n",
      "3800 movie plots cleaned\n",
      "3900 movie plots cleaned\n",
      "4000 movie plots cleaned\n",
      "4100 movie plots cleaned\n",
      "4200 movie plots cleaned\n",
      "4300 movie plots cleaned\n",
      "4400 movie plots cleaned\n",
      "4500 movie plots cleaned\n",
      "4600 movie plots cleaned\n",
      "4700 movie plots cleaned\n",
      "4800 movie plots cleaned\n",
      "4900 movie plots cleaned\n",
      "5000 movie plots cleaned\n",
      "5100 movie plots cleaned\n",
      "5200 movie plots cleaned\n",
      "5300 movie plots cleaned\n",
      "5400 movie plots cleaned\n",
      "5500 movie plots cleaned\n",
      "5600 movie plots cleaned\n",
      "5700 movie plots cleaned\n",
      "5800 movie plots cleaned\n",
      "5900 movie plots cleaned\n",
      "6000 movie plots cleaned\n",
      "6100 movie plots cleaned\n",
      "6200 movie plots cleaned\n",
      "6300 movie plots cleaned\n",
      "6400 movie plots cleaned\n",
      "6500 movie plots cleaned\n",
      "6600 movie plots cleaned\n",
      "6700 movie plots cleaned\n",
      "6800 movie plots cleaned\n",
      "6900 movie plots cleaned\n",
      "7000 movie plots cleaned\n",
      "7100 movie plots cleaned\n",
      "7200 movie plots cleaned\n",
      "7300 movie plots cleaned\n",
      "7400 movie plots cleaned\n",
      "7500 movie plots cleaned\n",
      "7600 movie plots cleaned\n",
      "7700 movie plots cleaned\n",
      "7800 movie plots cleaned\n",
      "7900 movie plots cleaned\n",
      "8000 movie plots cleaned\n",
      "8100 movie plots cleaned\n",
      "8200 movie plots cleaned\n",
      "8300 movie plots cleaned\n",
      "8400 movie plots cleaned\n",
      "8500 movie plots cleaned\n",
      "8600 movie plots cleaned\n",
      "8700 movie plots cleaned\n",
      "8800 movie plots cleaned\n",
      "8900 movie plots cleaned\n",
      "9000 movie plots cleaned\n",
      "9100 movie plots cleaned\n",
      "9200 movie plots cleaned\n",
      "9300 movie plots cleaned\n",
      "9400 movie plots cleaned\n",
      "9500 movie plots cleaned\n",
      "9600 movie plots cleaned\n",
      "9700 movie plots cleaned\n",
      "9800 movie plots cleaned\n",
      "9900 movie plots cleaned\n",
      "10000 movie plots cleaned\n",
      "10100 movie plots cleaned\n",
      "10200 movie plots cleaned\n",
      "10300 movie plots cleaned\n",
      "10400 movie plots cleaned\n",
      "10500 movie plots cleaned\n",
      "10600 movie plots cleaned\n",
      "10700 movie plots cleaned\n",
      "10800 movie plots cleaned\n",
      "10900 movie plots cleaned\n",
      "11000 movie plots cleaned\n",
      "11100 movie plots cleaned\n",
      "11200 movie plots cleaned\n",
      "11300 movie plots cleaned\n",
      "11400 movie plots cleaned\n",
      "11500 movie plots cleaned\n",
      "11600 movie plots cleaned\n",
      "11700 movie plots cleaned\n",
      "11800 movie plots cleaned\n",
      "11900 movie plots cleaned\n",
      "12000 movie plots cleaned\n",
      "12100 movie plots cleaned\n",
      "12200 movie plots cleaned\n",
      "12300 movie plots cleaned\n",
      "12400 movie plots cleaned\n",
      "12500 movie plots cleaned\n",
      "12600 movie plots cleaned\n",
      "12700 movie plots cleaned\n",
      "12800 movie plots cleaned\n",
      "12900 movie plots cleaned\n",
      "13000 movie plots cleaned\n",
      "13100 movie plots cleaned\n",
      "13200 movie plots cleaned\n",
      "13300 movie plots cleaned\n",
      "13400 movie plots cleaned\n",
      "13500 movie plots cleaned\n",
      "13600 movie plots cleaned\n",
      "13700 movie plots cleaned\n",
      "13800 movie plots cleaned\n",
      "13900 movie plots cleaned\n",
      "14000 movie plots cleaned\n",
      "14100 movie plots cleaned\n",
      "14200 movie plots cleaned\n",
      "14300 movie plots cleaned\n",
      "14400 movie plots cleaned\n",
      "14500 movie plots cleaned\n",
      "14600 movie plots cleaned\n",
      "14700 movie plots cleaned\n",
      "14800 movie plots cleaned\n",
      "14900 movie plots cleaned\n",
      "15000 movie plots cleaned\n",
      "15100 movie plots cleaned\n",
      "15200 movie plots cleaned\n",
      "15300 movie plots cleaned\n",
      "15400 movie plots cleaned\n",
      "15500 movie plots cleaned\n",
      "15600 movie plots cleaned\n",
      "15700 movie plots cleaned\n",
      "15800 movie plots cleaned\n",
      "15900 movie plots cleaned\n",
      "16000 movie plots cleaned\n",
      "16100 movie plots cleaned\n",
      "16200 movie plots cleaned\n",
      "16300 movie plots cleaned\n",
      "16400 movie plots cleaned\n",
      "16500 movie plots cleaned\n",
      "16600 movie plots cleaned\n",
      "16700 movie plots cleaned\n",
      "16800 movie plots cleaned\n",
      "16900 movie plots cleaned\n",
      "17000 movie plots cleaned\n",
      "17100 movie plots cleaned\n",
      "17200 movie plots cleaned\n",
      "17300 movie plots cleaned\n",
      "17400 movie plots cleaned\n",
      "17500 movie plots cleaned\n",
      "17600 movie plots cleaned\n",
      "17700 movie plots cleaned\n",
      "17800 movie plots cleaned\n",
      "17900 movie plots cleaned\n",
      "18000 movie plots cleaned\n",
      "18100 movie plots cleaned\n",
      "18200 movie plots cleaned\n",
      "18300 movie plots cleaned\n",
      "18400 movie plots cleaned\n",
      "18500 movie plots cleaned\n",
      "18600 movie plots cleaned\n",
      "18700 movie plots cleaned\n",
      "18800 movie plots cleaned\n",
      "18900 movie plots cleaned\n",
      "19000 movie plots cleaned\n",
      "19100 movie plots cleaned\n",
      "19200 movie plots cleaned\n",
      "19300 movie plots cleaned\n",
      "19400 movie plots cleaned\n",
      "19500 movie plots cleaned\n",
      "19600 movie plots cleaned\n",
      "19700 movie plots cleaned\n",
      "19800 movie plots cleaned\n",
      "19900 movie plots cleaned\n",
      "20000 movie plots cleaned\n",
      "20100 movie plots cleaned\n",
      "20200 movie plots cleaned\n",
      "20300 movie plots cleaned\n",
      "20400 movie plots cleaned\n",
      "20500 movie plots cleaned\n",
      "20600 movie plots cleaned\n",
      "20700 movie plots cleaned\n",
      "20800 movie plots cleaned\n",
      "20900 movie plots cleaned\n",
      "21000 movie plots cleaned\n",
      "21100 movie plots cleaned\n",
      "21200 movie plots cleaned\n",
      "21300 movie plots cleaned\n",
      "21400 movie plots cleaned\n",
      "21500 movie plots cleaned\n",
      "21600 movie plots cleaned\n",
      "21700 movie plots cleaned\n",
      "21800 movie plots cleaned\n",
      "21900 movie plots cleaned\n",
      "22000 movie plots cleaned\n",
      "22100 movie plots cleaned\n",
      "22200 movie plots cleaned\n",
      "22300 movie plots cleaned\n",
      "22400 movie plots cleaned\n",
      "22500 movie plots cleaned\n",
      "22600 movie plots cleaned\n",
      "22700 movie plots cleaned\n",
      "22800 movie plots cleaned\n",
      "22900 movie plots cleaned\n",
      "23000 movie plots cleaned\n",
      "23100 movie plots cleaned\n",
      "23200 movie plots cleaned\n",
      "23300 movie plots cleaned\n",
      "23400 movie plots cleaned\n",
      "23500 movie plots cleaned\n",
      "23600 movie plots cleaned\n",
      "23700 movie plots cleaned\n",
      "23800 movie plots cleaned\n",
      "23900 movie plots cleaned\n",
      "24000 movie plots cleaned\n",
      "24100 movie plots cleaned\n",
      "24200 movie plots cleaned\n",
      "24300 movie plots cleaned\n",
      "24400 movie plots cleaned\n",
      "24500 movie plots cleaned\n",
      "24600 movie plots cleaned\n",
      "24700 movie plots cleaned\n",
      "24800 movie plots cleaned\n",
      "24900 movie plots cleaned\n",
      "25000 movie plots cleaned\n",
      "25100 movie plots cleaned\n",
      "25200 movie plots cleaned\n",
      "25300 movie plots cleaned\n",
      "25400 movie plots cleaned\n",
      "25500 movie plots cleaned\n",
      "25600 movie plots cleaned\n",
      "25700 movie plots cleaned\n",
      "25800 movie plots cleaned\n",
      "25900 movie plots cleaned\n",
      "26000 movie plots cleaned\n",
      "26100 movie plots cleaned\n",
      "26200 movie plots cleaned\n",
      "26300 movie plots cleaned\n",
      "26400 movie plots cleaned\n",
      "26500 movie plots cleaned\n",
      "26600 movie plots cleaned\n",
      "26700 movie plots cleaned\n",
      "26800 movie plots cleaned\n",
      "26900 movie plots cleaned\n",
      "27000 movie plots cleaned\n",
      "27100 movie plots cleaned\n",
      "27200 movie plots cleaned\n",
      "27300 movie plots cleaned\n",
      "27400 movie plots cleaned\n",
      "27500 movie plots cleaned\n",
      "27600 movie plots cleaned\n",
      "27700 movie plots cleaned\n",
      "27800 movie plots cleaned\n",
      "27900 movie plots cleaned\n",
      "28000 movie plots cleaned\n",
      "28100 movie plots cleaned\n",
      "28200 movie plots cleaned\n",
      "28300 movie plots cleaned\n",
      "28400 movie plots cleaned\n",
      "28500 movie plots cleaned\n",
      "28600 movie plots cleaned\n",
      "28700 movie plots cleaned\n",
      "28800 movie plots cleaned\n",
      "28900 movie plots cleaned\n",
      "29000 movie plots cleaned\n",
      "29100 movie plots cleaned\n",
      "29200 movie plots cleaned\n",
      "29300 movie plots cleaned\n",
      "29400 movie plots cleaned\n",
      "29500 movie plots cleaned\n",
      "29600 movie plots cleaned\n",
      "29700 movie plots cleaned\n",
      "29800 movie plots cleaned\n",
      "29900 movie plots cleaned\n",
      "30000 movie plots cleaned\n",
      "30100 movie plots cleaned\n",
      "30200 movie plots cleaned\n",
      "30300 movie plots cleaned\n",
      "30400 movie plots cleaned\n",
      "30500 movie plots cleaned\n",
      "30600 movie plots cleaned\n",
      "30700 movie plots cleaned\n",
      "30800 movie plots cleaned\n",
      "30900 movie plots cleaned\n",
      "31000 movie plots cleaned\n",
      "31100 movie plots cleaned\n",
      "31200 movie plots cleaned\n",
      "31300 movie plots cleaned\n",
      "31400 movie plots cleaned\n",
      "31500 movie plots cleaned\n",
      "31600 movie plots cleaned\n",
      "31700 movie plots cleaned\n",
      "31800 movie plots cleaned\n",
      "31900 movie plots cleaned\n",
      "32000 movie plots cleaned\n",
      "32100 movie plots cleaned\n",
      "32200 movie plots cleaned\n",
      "32300 movie plots cleaned\n",
      "32400 movie plots cleaned\n",
      "32500 movie plots cleaned\n",
      "32600 movie plots cleaned\n",
      "32700 movie plots cleaned\n",
      "32800 movie plots cleaned\n",
      "32900 movie plots cleaned\n",
      "33000 movie plots cleaned\n",
      "33100 movie plots cleaned\n",
      "33200 movie plots cleaned\n",
      "33300 movie plots cleaned\n",
      "33400 movie plots cleaned\n",
      "33500 movie plots cleaned\n",
      "33600 movie plots cleaned\n",
      "33700 movie plots cleaned\n",
      "33800 movie plots cleaned\n",
      "33900 movie plots cleaned\n",
      "34000 movie plots cleaned\n",
      "34100 movie plots cleaned\n",
      "34200 movie plots cleaned\n",
      "34300 movie plots cleaned\n",
      "34400 movie plots cleaned\n",
      "34500 movie plots cleaned\n",
      "34600 movie plots cleaned\n",
      "34700 movie plots cleaned\n",
      "34800 movie plots cleaned\n",
      "Grace Roberts played Lea Leland marries rancher Edward Smith revealed neglectful vice ridden spouse daughter Vivian Dr. Franklin Leonid Samoloff whisks Grace away unhappy life New York aliases pretending married surely Smith agree divorce Grace Franklin son Walter Milton S. Gould Vivian gets sick Grace Franklin return save reunion Smith assumed Grace dead causes death Franklin plot device frees Grace return father farm children.[1\n"
     ]
    }
   ],
   "source": [
    "# Add column to Plots of plot without stopwords and punctuation - plots[id][2]\n",
    "cleaned_plots = []\n",
    "counter = 0\n",
    "\n",
    "for plot in plots:\n",
    "    if debug:\n",
    "        counter+=1\n",
    "        if (counter % 100 == 0):\n",
    "            print(counter, \"movie plots cleaned\")\n",
    "    token_list = []\n",
    "    for token in plot[1]:\n",
    "        if not nlp.vocab[token.text].is_stop and not nlp.vocab[token.text].is_punct and not token.text == \"\\n\":\n",
    "            token_list.append(token.text)\n",
    "\n",
    "    cleaned_plots.append([plot[0], nlp(' '.join(str(token) for token in token_list))])\n",
    "\n",
    "print(cleaned_plots[100][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top10_match_cleaned_plots(id):\n",
    "    if debug:\n",
    "        start_time = process_time()\n",
    "    matches = [['BASE VALUE', 0]] # Schema: [ [title, score], [title, score]... ]\n",
    "    \n",
    "    for plot in cleaned_plots:\n",
    "        if plot == cleaned_plots[id]:\n",
    "            continue\n",
    "\n",
    "        score = cleaned_plots[id][1].similarity(plot[1]) # Get Similarity between current movie and match movie\n",
    "\n",
    "        matches.append([plot[0], score]) # Add movie title and score to end of list\n",
    "        matches = sorted(matches, key=lambda x: x[1], reverse=True) # Sort list by scores\n",
    "        if len(matches) > 10: # Remove lowest score if length > 10\n",
    "            matches.pop()\n",
    "    \n",
    "    end_time = process_time()\n",
    "    # Print Results\n",
    "    print(\"The best matches for\", cleaned_plots[id][0], \"are:\")\n",
    "    i = 1\n",
    "    for match in matches:\n",
    "        print(str(i) + \".\", match[0], \"\\t\", match[1])\n",
    "        i+=1\n",
    "\n",
    "    print(\"\\nTime to find best match from \", len(cleaned_plots), \" films: \", end_time - start_time)\n",
    "    print(\"Average search time per film: \", (end_time-start_time)/len(cleaned_plots))\n",
    "\n",
    "top10_match_cleaned_plots(3331)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed  1000  movies\n",
      "Processed  2000  movies\n",
      "Processed  3000  movies\n",
      "Processed  4000  movies\n",
      "Processed  5000  movies\n",
      "Processed  6000  movies\n",
      "Processed  7000  movies\n",
      "Processed  8000  movies\n",
      "Processed  9000  movies\n",
      "Processed  10000  movies\n",
      "Processed  11000  movies\n",
      "Processed  12000  movies\n",
      "Processed  13000  movies\n",
      "Processed  14000  movies\n",
      "Processed  15000  movies\n",
      "Processed  16000  movies\n",
      "Processed  17000  movies\n",
      "Processed  18000  movies\n",
      "Processed  19000  movies\n",
      "Processed  20000  movies\n",
      "Processed  21000  movies\n",
      "Processed  22000  movies\n",
      "Processed  23000  movies\n",
      "Processed  24000  movies\n",
      "Processed  25000  movies\n",
      "Processed  26000  movies\n",
      "Processed  27000  movies\n",
      "Processed  28000  movies\n",
      "Processed  29000  movies\n",
      "Processed  30000  movies\n",
      "Processed  31000  movies\n",
      "Processed  32000  movies\n",
      "Processed  33000  movies\n",
      "Processed  34000  movies\n",
      "Processed all  34886  movies\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import io\n",
    "\n",
    "best_cleaned_matches=list()\n",
    "\n",
    "count = 0\n",
    "\n",
    "for plot in cleaned_plots:\n",
    "    matches = [['BASE VALUE', 0]] # Schema: [ [title, score], [title, score]... ]\n",
    "    \n",
    "    for compplot in cleaned_plots:\n",
    "        if compplot == plot:\n",
    "            continue\n",
    "\n",
    "        score = plot[1].similarity(compplot[1]) # Get Similarity between current movie and match movie\n",
    "\n",
    "        matches.append([compplot[0], score]) # Add movie title and score to end of list\n",
    "        matches = sorted(matches, key=lambda x: x[1], reverse=True) # Sort list by scores\n",
    "        if len(matches) > 10: # Remove lowest score if length > 10\n",
    "            matches.pop()\n",
    "    \n",
    "    best_cleaned_matches.append((plot[0],matches))\n",
    "    count = count + 1\n",
    "    if(count % 1000 == 0):\n",
    "        print(\"Processed \", count, \" movies\")\n",
    "print (\"Processed all \", count, \" movies\")\n",
    "\n",
    "f = open('toptencleanedwords.dat','wb')\n",
    "pickle.dump(best_cleaned_matches,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Take Plots[10] and Plots[100] and remove the stopwords\n",
    "# TODO: Find more efficient way to remove stopwords\n",
    "# TODO: Remove stopwords from ALL plots\n",
    "\n",
    "# Create blank token list\n",
    "first_token_list = []\n",
    "# Tokenize plots - add each word to list\n",
    "for token in plots[10][1]:\n",
    "    first_token_list.append(token.text)\n",
    "\n",
    "# Create a new string combining all the tokens (words) that are not stopwords\n",
    "first_filtered_plot_str = ' '.join([str(token) for token in first_token_list if not nlp.vocab[token].is_stop])\n",
    "\n",
    "# Repeat stopword removal for second plot\n",
    "second_token_list = []\n",
    "for token in plots[100][1]:\n",
    "    second_token_list.append(token.text)      \n",
    "\n",
    "second_filtered_plot_str = ' '.join([str(token) for token in second_token_list if not nlp.vocab[token].is_stop])\n",
    "\n",
    "# Print standard simularity with stopwords\n",
    "simularity_printer(10, 100)\n",
    "\n",
    "# Print Filtered Stopword similarity to test stopword removal impact\n",
    "print(\"Filtered Stopwords: \", nlp(first_filtered_plot_str).similarity(nlp(second_filtered_plot_str)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiments with bag of words for keyword group mining\n",
    "from bitarray import bitarray\n",
    "from apyori import apriori\n",
    "\n",
    "\n",
    "lexicon = {}\n",
    "for plot in plots:\n",
    "    for token in plot[1]:\n",
    "        if not nlp.vocab[token.text].is_stop and not nlp.vocab[token.text].is_punct and not token.text == \"\\n\":\n",
    "            if token.lemma_ not in lexicon.keys():\n",
    "                lexicon[token.lemma_] = 1\n",
    "            else:\n",
    "                lexicon[token.lemma_] += 1\n",
    "\n",
    "print(list(lexicon)[0:25])\n",
    "print(len(lexicon))\n",
    "\n",
    "plot_word_bags = []\n",
    "plot_word_lists = []\n",
    "\n",
    "for plot in plots:\n",
    "    plot_words = set()\n",
    "    plot_words_list = []\n",
    "    for token in plot[1]:\n",
    "        if not nlp.vocab[token.text].is_stop and not nlp.vocab[token.text].is_punct:\n",
    "            plot_words.add(token.lemma_)\n",
    "    word_bag = bitarray()\n",
    "    for word in lexicon:\n",
    "        if word in plot_words:\n",
    "            word_bag.append(1)\n",
    "            plot_words_list.append(word)\n",
    "        else:\n",
    "            word_bag.append(0)\n",
    "    plot_word_bags.append(word_bag)\n",
    "    plot_word_lists.append(plot_words_list)\n",
    "\n",
    "plot_num = 400\n",
    "#print(plots[plot_num][0])\n",
    "#print(plot_word_bags[plot_num])\n",
    "#for i in range(0, len(lexicon)):\n",
    "#    if plot_word_bags[plot_num][i]:\n",
    "#        print(list(lexicon.keys())[i])\n",
    "\n",
    "#Ignore compact bit vectors for now, see what happens with an out of the box apriori algorithm\n",
    "results = list(apriori(plot_word_lists, min_support = .1))\n",
    "print(\"Apriori Test\")\n",
    "print(\"Total results: \", len(results))\n",
    "for result in results:\n",
    "    print(result.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def supportSorter(e):\n",
    "  return e.support\n",
    "\n",
    "results.sort( key=supportSorter)\n",
    "\n",
    "for result in results:\n",
    "  print(result.items, result.support)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movie Processing Finished\n",
      "1000000  ratings processed\n",
      "2000000  ratings processed\n",
      "3000000  ratings processed\n",
      "4000000  ratings processed\n",
      "5000000  ratings processed\n",
      "6000000  ratings processed\n",
      "7000000  ratings processed\n",
      "8000000  ratings processed\n",
      "9000000  ratings processed\n",
      "10000000  ratings processed\n",
      "11000000  ratings processed\n",
      "12000000  ratings processed\n",
      "13000000  ratings processed\n",
      "14000000  ratings processed\n",
      "15000000  ratings processed\n",
      "16000000  ratings processed\n",
      "17000000  ratings processed\n",
      "18000000  ratings processed\n",
      "19000000  ratings processed\n",
      "20000000  ratings processed\n",
      "21000000  ratings processed\n",
      "22000000  ratings processed\n",
      "23000000  ratings processed\n",
      "24000000  ratings processed\n",
      "25000000  ratings processed\n",
      "26000000  ratings processed\n",
      "Finished processing all  26024289  ratings\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import csv\n",
    "\n",
    "rated_movies = set()\n",
    "rated_movies_dict = {}\n",
    "#movie_ratings = set()\n",
    "movie_viewers = defaultdict(lambda: {})\n",
    "viewer_movies = defaultdict(lambda: list())\n",
    "\n",
    "\n",
    "with open(\"movies_metadata.csv\", 'r', encoding='utf-8') as movie_meta_data:\n",
    "    movie_reader = csv.reader(movie_meta_data)\n",
    "    next(movie_reader, None)  # Skip the csv header row\n",
    "\n",
    "    for row in movie_reader:\n",
    "        #print(row[5])\n",
    "        #print(row[8])\n",
    "        rated_movies.add((row[5],row[8]))\n",
    "        rated_movies_dict[row[8]]=row[5]\n",
    "\n",
    "print(\"Movie Processing Finished\")\n",
    "\n",
    "#userId,movieId,rating,timestamp\n",
    "with open(\"ratings.csv\", 'r', encoding='utf-8') as movie_ratings_data:\n",
    "    ratings_reader = csv.reader(movie_ratings_data)\n",
    "    next(ratings_reader, None)\n",
    "    count = 0\n",
    "\n",
    "    for row in ratings_reader:\n",
    "        count = count + 1\n",
    "        if(count % 1000000 == 0):\n",
    "            print(count, \" ratings processed\")\n",
    "       # movie_ratings.add((row[0],row[1],row[2]))\n",
    "        movie_viewers[row[1]][row[0]]=(row[0],row[1],float(row[2]))\n",
    "       # viewer_movies[row[0]].add((row[0],row[1],row[2]))\n",
    "    print(\"Finished processing all \", count, \" ratings\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Given a movie return the count of both how many people who liked the first movie liked the second movie\n",
    "# and how many people who liked the first movie didn't like the second movie\n",
    "def rating_comparison(base_movie_name, comparison_movie_name):\n",
    "    if(base_movie_name not in rated_movies_dict):\n",
    "        return (0, 0)\n",
    "    if(comparison_movie_name not in rated_movies_dict):\n",
    "        return (0, 0)\n",
    "    base_movie_id = rated_movies_dict[base_movie_name]\n",
    "    comparison_movie_id=rated_movies_dict[comparison_movie_name]\n",
    "    #print(base_movie_id)\n",
    "    #print(comparison_movie_id)\n",
    "    good_match = 0\n",
    "    bad_match = 0\n",
    "    for base_viewer_id in movie_viewers[base_movie_id]:\n",
    "        base_viewer = movie_viewers[base_movie_id][base_viewer_id]\n",
    "        if(base_viewer[2] >= 4):\n",
    "            if base_viewer[0] in movie_viewers[comparison_movie_id]:\n",
    "                comparison_viewer = movie_viewers[comparison_movie_id][base_viewer[0]]\n",
    "                if(comparison_viewer[2] >= 4):\n",
    "                    good_match = good_match + 1\n",
    "                elif(comparison_viewer[2] <= 3):\n",
    "                    bad_match = bad_match +1\n",
    "    #print(\"Good Matches: \", good_match)\n",
    "    #print(\"Bad Matches: \", bad_match)\n",
    "    return(good_match, bad_match)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 22)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_comparison(\"The Matrix\", \"The Fifth Element\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pre-matched list to test new rating method\n",
    "import pickle\n",
    "\n",
    "import io\n",
    "\n",
    "f = open('toptencleanedwords.dat','rb')\n",
    "best_cleaned_matches = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500  movies processed\n",
      "1000  movies processed\n",
      "1500  movies processed\n",
      "2000  movies processed\n",
      "2500  movies processed\n",
      "3000  movies processed\n",
      "3500  movies processed\n",
      "4000  movies processed\n",
      "4500  movies processed\n",
      "5000  movies processed\n",
      "5500  movies processed\n",
      "6000  movies processed\n",
      "6500  movies processed\n",
      "7000  movies processed\n",
      "7500  movies processed\n",
      "8000  movies processed\n",
      "8500  movies processed\n",
      "9000  movies processed\n",
      "9500  movies processed\n",
      "10000  movies processed\n",
      "10500  movies processed\n",
      "11000  movies processed\n",
      "11500  movies processed\n",
      "12000  movies processed\n",
      "12500  movies processed\n",
      "13000  movies processed\n",
      "13500  movies processed\n",
      "14000  movies processed\n",
      "14500  movies processed\n",
      "15000  movies processed\n",
      "15500  movies processed\n",
      "16000  movies processed\n",
      "16500  movies processed\n",
      "17000  movies processed\n",
      "17500  movies processed\n",
      "18000  movies processed\n",
      "18500  movies processed\n",
      "19000  movies processed\n",
      "19500  movies processed\n",
      "20000  movies processed\n",
      "20500  movies processed\n",
      "21000  movies processed\n",
      "21500  movies processed\n",
      "22000  movies processed\n",
      "22500  movies processed\n",
      "23000  movies processed\n",
      "23500  movies processed\n",
      "24000  movies processed\n",
      "24500  movies processed\n",
      "25000  movies processed\n",
      "25500  movies processed\n",
      "26000  movies processed\n",
      "26500  movies processed\n",
      "27000  movies processed\n",
      "27500  movies processed\n",
      "28000  movies processed\n",
      "28500  movies processed\n",
      "29000  movies processed\n",
      "29500  movies processed\n",
      "30000  movies processed\n",
      "30500  movies processed\n",
      "31000  movies processed\n",
      "31500  movies processed\n",
      "32000  movies processed\n",
      "32500  movies processed\n",
      "33000  movies processed\n",
      "33500  movies processed\n",
      "34000  movies processed\n",
      "34500  movies processed\n",
      "Total Good / Badd matches\n",
      "485147\n",
      "125259\n"
     ]
    }
   ],
   "source": [
    "total_good_matches = 0\n",
    "total_bad_matches = 0\n",
    "count = 0\n",
    "for movie_matches in best_matches:\n",
    "    for match in movie_matches[1]:\n",
    "        temp_score = rating_comparison(movie_matches[0], match[0])\n",
    "        total_good_matches = total_good_matches + temp_score[0]\n",
    "        total_bad_matches = total_bad_matches + temp_score[1]\n",
    "    count = count + 1\n",
    "    if(count%500 == 0):\n",
    "        print(count , \" movies processed\")\n",
    "print(\"Total Good / Bad matches\")\n",
    "print(total_good_matches)\n",
    "print(total_bad_matches)\n",
    "#rating_comparison(best_matches[test_movie_id][0],best_matches[test_movie_id][1][3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500  movies processed\n",
      "1000  movies processed\n",
      "1500  movies processed\n",
      "2000  movies processed\n",
      "2500  movies processed\n",
      "3000  movies processed\n",
      "3500  movies processed\n",
      "4000  movies processed\n",
      "4500  movies processed\n",
      "5000  movies processed\n",
      "5500  movies processed\n",
      "6000  movies processed\n",
      "6500  movies processed\n",
      "7000  movies processed\n",
      "7500  movies processed\n",
      "8000  movies processed\n",
      "8500  movies processed\n",
      "9000  movies processed\n",
      "9500  movies processed\n",
      "10000  movies processed\n",
      "10500  movies processed\n",
      "11000  movies processed\n",
      "11500  movies processed\n",
      "12000  movies processed\n",
      "12500  movies processed\n",
      "13000  movies processed\n",
      "13500  movies processed\n",
      "14000  movies processed\n",
      "14500  movies processed\n",
      "15000  movies processed\n",
      "15500  movies processed\n",
      "16000  movies processed\n",
      "16500  movies processed\n",
      "17000  movies processed\n",
      "17500  movies processed\n",
      "18000  movies processed\n",
      "18500  movies processed\n",
      "19000  movies processed\n",
      "19500  movies processed\n",
      "20000  movies processed\n",
      "20500  movies processed\n",
      "21000  movies processed\n",
      "21500  movies processed\n",
      "22000  movies processed\n",
      "22500  movies processed\n",
      "23000  movies processed\n",
      "23500  movies processed\n",
      "24000  movies processed\n",
      "24500  movies processed\n",
      "25000  movies processed\n",
      "25500  movies processed\n",
      "26000  movies processed\n",
      "26500  movies processed\n",
      "27000  movies processed\n",
      "27500  movies processed\n",
      "28000  movies processed\n",
      "28500  movies processed\n",
      "29000  movies processed\n",
      "29500  movies processed\n",
      "30000  movies processed\n",
      "30500  movies processed\n",
      "31000  movies processed\n",
      "31500  movies processed\n",
      "32000  movies processed\n",
      "32500  movies processed\n",
      "33000  movies processed\n",
      "33500  movies processed\n",
      "34000  movies processed\n",
      "34500  movies processed\n",
      "Total Good / Bad matches\n",
      "533483\n",
      "127712\n"
     ]
    }
   ],
   "source": [
    "total_good_matches = 0\n",
    "total_bad_matches = 0\n",
    "count = 0\n",
    "for movie_matches in best_cleaned_matches:\n",
    "    for match in movie_matches[1]:\n",
    "        temp_score = rating_comparison(movie_matches[0], match[0])\n",
    "        total_good_matches = total_good_matches + temp_score[0]\n",
    "        total_bad_matches = total_bad_matches + temp_score[1]\n",
    "    count = count + 1\n",
    "    if(count%500 == 0):\n",
    "        print(count , \" movies processed\")\n",
    "print(\"Total Good / Bad matches\")\n",
    "print(total_good_matches)\n",
    "print(total_bad_matches)\n",
    "#rating_comparison(best_matches[test_movie_id][0],best_matches[test_movie_id][1][3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500  movies processed\n",
      "1000  movies processed\n",
      "1500  movies processed\n",
      "2000  movies processed\n",
      "2500  movies processed\n",
      "3000  movies processed\n",
      "3500  movies processed\n",
      "4000  movies processed\n",
      "4500  movies processed\n",
      "5000  movies processed\n",
      "5500  movies processed\n",
      "6000  movies processed\n",
      "6500  movies processed\n",
      "7000  movies processed\n",
      "7500  movies processed\n",
      "8000  movies processed\n",
      "8500  movies processed\n",
      "9000  movies processed\n",
      "9500  movies processed\n",
      "10000  movies processed\n",
      "10500  movies processed\n",
      "11000  movies processed\n",
      "11500  movies processed\n",
      "12000  movies processed\n",
      "12500  movies processed\n",
      "13000  movies processed\n",
      "13500  movies processed\n",
      "14000  movies processed\n",
      "14500  movies processed\n",
      "15000  movies processed\n",
      "15500  movies processed\n",
      "16000  movies processed\n",
      "16500  movies processed\n",
      "17000  movies processed\n",
      "17500  movies processed\n",
      "18000  movies processed\n",
      "18500  movies processed\n",
      "19000  movies processed\n",
      "19500  movies processed\n",
      "20000  movies processed\n",
      "20500  movies processed\n",
      "21000  movies processed\n",
      "21500  movies processed\n",
      "22000  movies processed\n",
      "22500  movies processed\n",
      "23000  movies processed\n",
      "23500  movies processed\n",
      "24000  movies processed\n",
      "24500  movies processed\n",
      "25000  movies processed\n",
      "25500  movies processed\n",
      "26000  movies processed\n",
      "26500  movies processed\n",
      "27000  movies processed\n",
      "27500  movies processed\n",
      "28000  movies processed\n",
      "28500  movies processed\n",
      "29000  movies processed\n",
      "29500  movies processed\n",
      "30000  movies processed\n",
      "30500  movies processed\n",
      "31000  movies processed\n",
      "31500  movies processed\n",
      "32000  movies processed\n",
      "32500  movies processed\n",
      "33000  movies processed\n",
      "33500  movies processed\n",
      "34000  movies processed\n",
      "34500  movies processed\n",
      "Total Good / Bad matches\n",
      "465905\n",
      "86833\n"
     ]
    }
   ],
   "source": [
    "#Stop word version had better results than plain smiilarity\n",
    "#Does ignoring low simularity matches make it even better?\n",
    "total_good_matches = 0\n",
    "total_bad_matches = 0\n",
    "count = 0\n",
    "for movie_matches in best_cleaned_matches:\n",
    "    for match in movie_matches[1]:\n",
    "        if(match[1] > 0.95):\n",
    "            temp_score = rating_comparison(movie_matches[0], match[0])\n",
    "            total_good_matches = total_good_matches + temp_score[0]\n",
    "            total_bad_matches = total_bad_matches + temp_score[1]\n",
    "    count = count + 1\n",
    "    if(count%500 == 0):\n",
    "        print(count , \" movies processed\")\n",
    "print(\"Total Good / Bad matches\")\n",
    "print(total_good_matches)\n",
    "print(total_bad_matches)\n",
    "#rating_comparison(best_matches[test_movie_id][0],best_matches[test_movie_id][1][3][0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
