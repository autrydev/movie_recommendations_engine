{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Necessary Libraries and Packages\n",
    "import sys  \n",
    "import csv\n",
    "import spacy\n",
    "from time import process_time\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Set global variables\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500  movies processed\n",
      "1000  movies processed\n",
      "1500  movies processed\n",
      "2000  movies processed\n",
      "2500  movies processed\n",
      "3000  movies processed\n",
      "Processing Done\n",
      "Time to process  3248  records:  195.734375\n",
      "Average processing timer per record:  0.060263046490147784\n",
      "('Should a Woman Divorce?', Grace Roberts (played by Lea Leland), marries rancher Edward Smith, who is revealed to be a neglectful, vice-ridden spouse. They have a daughter, Vivian. Dr. Franklin (Leonid Samoloff) whisks Grace away from this unhappy life, and they move to New York under aliases, pretending to be married (since surely Smith would not agree to a divorce). Grace and Franklin have a son, Walter (Milton S. Gould). Vivian gets sick, however, and Grace and Franklin return to save her. Somehow this reunion, as Smith had assumed Grace to be dead, causes the death of Franklin. This plot device frees Grace to return to her father's farm with both children.[1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if debug:\n",
    "    start_time = process_time()\n",
    "\n",
    "# Set the appropriate input file\n",
    "movie_plots_import_file = \"wiki_movie_plots_sample.csv\"\n",
    "\n",
    "# Setup the plots array\n",
    "plots = []\n",
    "\n",
    "# Open import file and export all plots and titles into plots[]\n",
    "with open(movie_plots_import_file, 'r', encoding='utf-8') as movie_plot_csv_file:\n",
    "    reader = csv.reader(movie_plot_csv_file)\n",
    "    next(reader, None)  # Skip the csv header row\n",
    "    count=0\n",
    "\n",
    "    for row in reader:\n",
    "        plots.append((row[1],nlp(row[7])))\n",
    "        count = count + 1\n",
    "        if(count % 500 == 0):\n",
    "            print(count, \" movies processed\")\n",
    "            \n",
    "print(\"Processing Done\")\n",
    "\n",
    "if debug:\n",
    "    end_time = process_time()\n",
    "    print(\"Time to process \", count, \" records: \", end_time - start_time)\n",
    "    print(\"Average processing timer per record: \", (end_time- start_time)/count)\n",
    "\n",
    "# Print example when finished\n",
    "print(plots[100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define generic similarity function\n",
    "def simularity_printer(firstId, secondId):\n",
    "    if debug:\n",
    "        start_time = process_time()\n",
    "    print(\"Similarity of \", plots[firstId][0], \" and \", plots[secondId][0], \":\", plots[firstId][1].similarity(plots[secondId][1]))\n",
    "    if debug:\n",
    "        end_time = process_time()\n",
    "        print(\"Simularity calculation runtime \", end_time - start_time)\n",
    "\n",
    "# Define generic 'best match' function\n",
    "def best_match(id):\n",
    "    if debug:\n",
    "        start_time = process_time()\n",
    "    best_score = 0\n",
    "    best_match = \"None\"\n",
    "    for plot in plots:\n",
    "        if plot == plots[id]:\n",
    "            continue\n",
    "        score = plots[id][1].similarity(plot[1])\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match = plot[0]\n",
    "    print(\"Best match for \",plots[id][0],\" was: \",best_match,\" with score of \", best_score)\n",
    "    if debug:\n",
    "        end_time = process_time()\n",
    "        print(\"Time to find best match from \", len(plots), \" films: \", end_time - start_time)\n",
    "        print(\"Average search time per film: \", (end_time-start_time)/len(plots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of  Dream of a Rarebit Fiend  and  Which Woman? : 0.9371971157790536\n",
      "Simularity calculation runtime  0.0\n",
      "Similarity of  Dream of a Rarebit Fiend  and  The Turn in the Road : 0.9343359550730539\n",
      "Simularity calculation runtime  0.0\n",
      "Similarity of  A Christmas Carol  and  Dough and Dynamite : 0.9311458919462225\n",
      "Simularity calculation runtime  0.0\n",
      "Similarity of  A Christmas Carol  and  Face Value : 0.9541526327456455\n",
      "Simularity calculation runtime  0.0\n",
      "Similarity of  A Christmas Carol  and  The Girl Who Stayed at Home : 0.9412193928939658\n",
      "Simularity calculation runtime  0.0\n",
      "Best match for  Top Hat  was:  The Awful Truth  with score of  0.9830821187041965\n",
      "Time to find best match from  34886  films:  0.28125\n",
      "Average search time per film:  8.061973284412086e-06\n",
      "Best match for  At the Circus  was:  Gold Diggers in Paris  with score of  0.9813152325737858\n",
      "Time to find best match from  34886  films:  0.234375\n",
      "Average search time per film:  6.718311070343404e-06\n",
      "Best match for  The Big Store  was:  Our Blushing Brides  with score of  0.9796873219737309\n",
      "Time to find best match from  34886  films:  0.25\n",
      "Average search time per film:  7.166198475032965e-06\n"
     ]
    }
   ],
   "source": [
    "# Print some tests/examples\n",
    "simularity_printer(10, 250)\n",
    "simularity_printer(10, 300)\n",
    "simularity_printer(27, 72)\n",
    "simularity_printer(27, 207)\n",
    "simularity_printer(27, 270)\n",
    "\n",
    "best_match(2000)\n",
    "best_match(2500)\n",
    "best_match(3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best match for  Rangers of Fortune  was:  Lonesome Dove  with score of  0.9851557247821526\n",
      "Time to find best match from  34886  films:  0.25\n",
      "Average search time per film:  7.166198475032965e-06\n"
     ]
    }
   ],
   "source": [
    "best_match(2915)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of  Dream of a Rarebit Fiend  and  Should a Woman Divorce? : 0.8760381240648998\n",
      "Filtered Stopwords:  0.7202336502162601\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Take Plots[10] and Plots[100] and remove the stopwords\n",
    "# TODO: Find more efficient way to remove stopwords\n",
    "# TODO: Remove stopwords from ALL plots\n",
    "\n",
    "# Create blank token list\n",
    "first_token_list = []\n",
    "# Tokenize plots - add each word to list\n",
    "for token in plots[10][1]:\n",
    "    first_token_list.append(token.text)\n",
    "\n",
    "# Create a new string combining all the tokens (words) that are not stopwords\n",
    "first_filtered_plot_str = ' '.join([str(token) for token in first_token_list if not nlp.vocab[token].is_stop])\n",
    "\n",
    "# Repeat stopword removal for second plot\n",
    "second_token_list = []\n",
    "for token in plots[100][1]:\n",
    "    second_token_list.append(token.text)      \n",
    "\n",
    "second_filtered_plot_str = ' '.join([str(token) for token in second_token_list if not nlp.vocab[token].is_stop])\n",
    "\n",
    "# Print standard simularity with stopwords\n",
    "simularity_printer(10, 100)\n",
    "\n",
    "# Print Filtered Stopword similarity to test stopword removal impact\n",
    "print(\"Filtered Stopwords: \", nlp(first_filtered_plot_str).similarity(nlp(second_filtered_plot_str)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bartender', 'work', 'saloon', 'serve', 'drink', 'customer', 'fill', 'stereotypically', 'irish', 'man', 'bucket', 'beer', 'Carrie', 'Nation', 'follower', 'burst', 'inside', 'assault', 'pull', 'hat', 'eye', 'dump', 'head', 'group', 'begin']\n",
      "28380\n",
      "Apriori Test\n",
      "Total results:  487\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'frozenset' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sc\\Documents\\ufo\\cap4770_machine_learning\\final project\\plot_based_movie_recomendations\\spacy_experiments.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sc/Documents/ufo/cap4770_machine_learning/final%20project/plot_based_movie_recomendations/spacy_experiments.ipynb#ch0000009?line=46'>47</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTotal results: \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mlen\u001b[39m(results))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sc/Documents/ufo/cap4770_machine_learning/final%20project/plot_based_movie_recomendations/spacy_experiments.ipynb#ch0000009?line=47'>48</a>\u001b[0m \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m results:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sc/Documents/ufo/cap4770_machine_learning/final%20project/plot_based_movie_recomendations/spacy_experiments.ipynb#ch0000009?line=48'>49</a>\u001b[0m     \u001b[39mif\u001b[39;00m(\u001b[39mlen\u001b[39m(result\u001b[39m.\u001b[39;49mitems \u001b[39m>\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sc/Documents/ufo/cap4770_machine_learning/final%20project/plot_based_movie_recomendations/spacy_experiments.ipynb#ch0000009?line=49'>50</a>\u001b[0m         \u001b[39mprint\u001b[39m(result\u001b[39m.\u001b[39mitems)\n",
      "\u001b[1;31mTypeError\u001b[0m: '>=' not supported between instances of 'frozenset' and 'int'"
     ]
    }
   ],
   "source": [
    "# Experiments with bag of words for keyword group mining\n",
    "from bitarray import bitarray\n",
    "from apyori import apriori\n",
    "\n",
    "\n",
    "lexicon = {}\n",
    "for plot in plots:\n",
    "    for token in plot[1]:\n",
    "        if not nlp.vocab[token.text].is_stop and not nlp.vocab[token.text].is_punct and not token.text == \"\\n\":\n",
    "            if token.lemma_ not in lexicon.keys():\n",
    "                lexicon[token.lemma_] = 1\n",
    "            else:\n",
    "                lexicon[token.lemma_] += 1\n",
    "\n",
    "print(list(lexicon)[0:25])\n",
    "print(len(lexicon))\n",
    "\n",
    "plot_word_bags = []\n",
    "plot_word_lists = []\n",
    "\n",
    "for plot in plots:\n",
    "    plot_words = set()\n",
    "    plot_words_list = []\n",
    "    for token in plot[1]:\n",
    "        if not nlp.vocab[token.text].is_stop and not nlp.vocab[token.text].is_punct:\n",
    "            plot_words.add(token.lemma_)\n",
    "    word_bag = bitarray()\n",
    "    for word in lexicon:\n",
    "        if word in plot_words:\n",
    "            word_bag.append(1)\n",
    "            plot_words_list.append(word)\n",
    "        else:\n",
    "            word_bag.append(0)\n",
    "    plot_word_bags.append(word_bag)\n",
    "    plot_word_lists.append(plot_words_list)\n",
    "\n",
    "plot_num = 400\n",
    "#print(plots[plot_num][0])\n",
    "#print(plot_word_bags[plot_num])\n",
    "#for i in range(0, len(lexicon)):\n",
    "#    if plot_word_bags[plot_num][i]:\n",
    "#        print(list(lexicon.keys())[i])\n",
    "\n",
    "#Ignore compact bit vectors for now, see what happens with an out of the box apriori algorithm\n",
    "results = list(apriori(plot_word_lists))\n",
    "print(\"Apriori Test\")\n",
    "print(\"Total results: \", len(results))\n",
    "for result in results:\n",
    "    if(len(result.items) >= 3):\n",
    "        print(result.items)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
